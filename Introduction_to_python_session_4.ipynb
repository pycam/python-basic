{
 "metadata": {
  "name": "Introduction_to_python_session_4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data input and output (I/O)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far, all that data we have been working with has been written by us into our scripts, and the results of out computation has just been displayed in the terminal output. In the real world data will be supplied by the user of our programs (who may be you!) by some means, and we will often want to save the results of some analysis somewhere more permanent than just printing it to the screen. In this session we cover 2 widely used ways of reading data into our programs, via the command line and by reading files from dish, we also discuss writing out data to files. \n",
      "\n",
      "There are, of course, many other ways of accessing data, such as querying a database or retrieving data from a network such as the internet. We don't cover these here, but python has excellent support for interacting with databases and networks either in the standard library or using external modules."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reading command line arguments\n",
      "\n",
      "A convenient way to supply arguments, such as data file names, algorithm parameters etc. to your script is via the command line used when you start your script running.\n",
      "\n",
      "All of the arguments supplied to your script are stored in an list which is available in the `sys` module we mentioned earlier, e.g. if you ran your script with a command line like:\n",
      "<br/>\n",
      "<tt>python script.py BRCA2 0.5</tt>\n",
      "<br/>\n",
      "<br/>\n",
      "Then the arguments `\"BRCA2\"` and `\"0.5\"` would be stored in `sys.argv` at the second and third positions, and the name of the script will be stored in first position in the list. You can access the elements of this list just like any other python list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat scripts/command.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python scripts/command.py 1 2 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that all the command line arguments are strings (even if they look like numbers on the command line), so if you want to operate on them as numbers you will need to cast them to the appropriate numerical type first. If you try to cast something that cannot be interpreted as the relevant type then python will raise a `ValueError` exception."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "int(\"not a number\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Exercises__\n",
      "\n",
      "1. Using the `sys` library, write a script that takes 2 integers from the command line, adds the 2 numbers and prints out the result. Your script will have to cast the string arguments to numbers, and it should check for a `ValueError` exception in case the user did not supply numbers. You should print out an error message in this case.\n",
      "2. Write a script that reads in a DNA sequence from the command line, and then prints out its length and GC percentage (using the code you wrote earlier on to compute the GC content)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__The `argparse` library__\n",
      "\n",
      "\n",
      "If you are developing a script and you want to read in standard unix command line options, i.e. those specified with a single or double hyphen such as `-h` or `--help`, there is a helpful library called `argparse` that you can use instead of directly operating on `sys.argv`. It also produces a helpful usage message. There are lots of options and settings, but here is a simple example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat scripts/argparse_example.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python scripts/argparse_example.py -h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python scripts/argparse_example.py -s GCGCTGTGCCTGCAATGATCGT -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Frequently the data we want to operate on or analyse will be stored in files, so in our programs we need to be able to open files, read through them (perhaps all at once, perhaps not), and then close them. \n",
      "\n",
      "We will also frequently want to be able to print output to files rather than always printing out results to the terminal.\n",
      "\n",
      "Python supports all of these modes of operations on files, and provides a number of useful functions and syntax to make dealing with files straightforward."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "File objects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To open a file, python provides the `open` function, which takes a filename as its first argument and returns a _file object_ which is python's internal representation of the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"data/datafile.txt\"\n",
      "fileObj = open( path )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`open` takes an optional second argument specifying the _mode_ in which the file is opened, either for reading, writing or appending."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"r\" ) # open for reading, default\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"w\" ) # open for writing (existing files will be overwritten)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"a\" ) # open for appending"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Mode modifiers__\n",
      "\n",
      "These mode strings can include some extra modifier characters that deal with issues in dealing with files across multiple platforms.\n",
      "\n",
      "`b`: binary mode, e.g. `\"rb\"`. No translation for end-of-line chanracters to platform specific setting value.\n",
      "\n",
      "`U`: universal new line mode, e.g. `\"rU\"`. Present end-of-line as `\"\\n\"` no matter where the file was written."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "File objects provide several methods for accessing data from and writing data to the file which we will see shortly, but you can also check the name of the file with `.name` attribute and the mode the file was opened in with `.mode`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fileObj.name\n",
      "print fileObj.mode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Error checking__\n",
      "\n",
      "If you try to open a file that doesn't exist, or that you don't have appropriate permissions to access python etc., will raise an `IOError` exception, which can catch with a `try` block as we saw yesterday."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    fileObj = open(\"doesnotexist.txt\", \"r\")\n",
      "    print fileObj.name\n",
      "except IOError:\n",
      "    print \"Oh no, we couldn't open our file!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Closing files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To close a file once you finished with it, you can call the `.close` method on a file object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading from files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we have opened a file for reading, file objects provide a number of methods for accessing the data in a file. The simplest of these is the `.read` method that reads the entire contents of the file into a string variable.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileObj = open( \"data/datafile.txt\" )\n",
      "print fileObj.read() # everything\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that if this means the entire file will be read into memory, if you are operating on a large file and don't actually need all the data at the same time this is rather inefficient.\n",
      "\n",
      "Frequently, we just need to operate on individuals lines of the file, and you can use the `.readline` method to read a line from a file and return it as a python string.\n",
      "\n",
      "File objects internally keep track of your current location in a file, so to get following lines from the file you can call this method multiple times.\n",
      "\n",
      "It is important to note that the string representing each line will have a trailing newline `\"\\n\"` character, which you may want to remove with the `.rstrip` string method.\n",
      "\n",
      "Once the end of the file is reached, `.readline` will return an empty string `''`. This is different from an apparently empty line in a file, as even an empty line will contain a newline character. Recall that the empty string is considered as `False` in python, so you can readily check for this condition with an `if` statement etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# one line at a time\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "print \"1st line: %r\" % fileObj.readline()\n",
      "print \"2nd line: %r\" % fileObj.readline()\n",
      "print \"3rd line: %r\" % fileObj.readline()\n",
      "print \"4th line: %r\" % fileObj.readline()\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To read in all lines from a file as a list of strings containing the data from each line, use the `.readlines` method (though note that this will again read all data into memory)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# all lines\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "\n",
      "lines = fileObj.readlines()\n",
      "\n",
      "print \"The file has\", len(lines), \"lines\"\n",
      "\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looping over the lines in a file is a very common operation and python lets you iterate over a file using a `for` loop just as if it were an array of strings. This does not read all data into memory at once, and so is much more efficient that reading the file with `.readlines` and then looping over the resulting list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# as an iterable\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "\n",
      "for line in fileObj:\n",
      "    print line.rstrip().upper()\n",
      "\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The with statement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is important that files are closed when they are no longer required, but writing ``fileObj.close()`` is tedious (and more importantly, easy to forget). An alternative syntax is to open the files within a ``with`` statement, in which case the file will automatically be closed at the end of the `with` block."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fileObj will be closed when leaving the block\n",
      "with open( \"data/datafile.txt\" ) as fileObj:\n",
      "    for ( i, line ) in enumerate( fileObj, start = 1 ):\n",
      "        print \"%s: %r\" % ( i, line )\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Writing to files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once a file has been opened for writing, you can use the `.write` method on a file object to write data to the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = open( \"out.txt\", \"w\" )\n",
      "output.write(\"GENE\\tREAD_COUNT\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The argument to the `.write` method must be a string, so if you want to write out numerical data to a file you will have to convert it to a string somehow beforehand.\n",
      "\n",
      "Remember to include a newline character to separate lines of your output, unlike the `print` statement, `.write` does not include this by default."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "read_counts = {\n",
      "    'BRCA2': 43234,\n",
      "    'FOXP2': 3245,\n",
      "    'SORT1': 343792\n",
      "}\n",
      "\n",
      "for gene in read_counts:\n",
      "    line = \"\\t\".join( [ gene, str(read_counts[gene]) ] )\n",
      "    output.write(line+\"\\n\")\n",
      "    \n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat out.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Be cautious when opening a file for writing, as python will happily let you overwrite any existing data in the file. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Exercises__\n",
      "\n",
      "1. Write a script that writes the values of a list of numbers to a file, with each number on a seperate line.\n",
      "\n",
      "2. Write a script that takes the name of a file containing many lines of nucleotide sequence as a command line argument and opens the file for reading (checking that the filename supplied does exist). For each line in the file, print out the line number and the length of the corresponding line (There is an example file <a href=\"http://www.ebi.ac.uk/~grsr/perl/dna.txt\">here</a> or in `data/dna.txt` from the course materials ).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data formats"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bioinformaticians love creating endless new file formats for their data, but there are a number of very common standard formats that it is good to get used to parsing.\n",
      "\n",
      "Fixed width (or columns):"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  \n",
      "ATOM    474  CA  SER A  92      10.391   7.707   5.748  1.00  0.87           C  \n",
      "ATOM    475  C   SER A  92      11.422   7.439   6.842  1.00  0.94           C  \n",
      "ATOM    476  O   SER A  92      12.423   8.118   6.941  1.00  1.07           O "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Delimited:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "X 169008682 1 111267453 1.0976\n",
      "2 8265484 5 69763543 4.9825\n",
      "MT 10924 MT 81934 7.2357\n",
      "3 127 8 10908776 1.2509"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Structured (or mark-up):"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "<PDBx:atom_site id=\"16809\">\n",
      "         <PDBx:Cartn_x>-5.882</PDBx:Cartn_x>\n",
      "         <PDBx:Cartn_y>-7.295</PDBx:Cartn_y>\n",
      "         <PDBx:Cartn_z>0.189</PDBx:Cartn_z>\n",
      "         <PDBx:label_asym_id>B</PDBx:label_asym_id>\n",
      "         <PDBx:label_atom_id>N</PDBx:label_atom_id>\n",
      "         <PDBx:label_comp_id>GLY</PDBx:label_comp_id>\n",
      "         <PDBx:label_entity_id>1</PDBx:label_entity_id>\n",
      "      </PDBx:atom_site>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Delimited files"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Reading delimited files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the various string manipulation techniques covered earlier to process delimited files in a fairly straightforward way. Here we loop through a file with columns delimited by spaces, reading the data for each row into a list, and storing each of these lists into a main results list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat data/mydata.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "\n",
      "with open(\"data/mydata.txt\", \"r\") as data:\n",
      "    header = data.readline()\n",
      "    for line in data:\n",
      "        line = line.strip()\n",
      "        results.append(line.split(\" \"))\n",
      "        \n",
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we show a slightly more complicated example where we reading the results into a more convenient data structure, a list of dictionaries with the dictionary keys corresponding to the column headers and the values to the values from each line. We also convert the columns to an appropriate type as we go."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "\n",
      "with open(\"data/mydata.txt\", \"r\") as data:\n",
      "    header = data.readline()\n",
      "    for line in data:\n",
      "        idx, org, score = line.strip().split(\" \")\n",
      "        row = {'index': int(idx), 'organism': org, 'score': float(score)}\n",
      "        results.append(row)\n",
      "        \n",
      "print results\n",
      "print 'Score of first row:', results[0]['score']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Writing delimited files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing out a delimited file is also straightforward using the `join` method, or possibly using format strings. Here, as an example we will recreate our original file from above, but this time we will delimit the columns with a comma."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/mydata.csv', 'w') as output:\n",
      "    # write a header, using the keys from the first dictionary\n",
      "    header = \",\".join(results[0].keys())\n",
      "    output.write(header + \"\\n\")\n",
      "    for row in results:\n",
      "        vals = [str(v) for v in row.values()]\n",
      "        row_line = \",\".join(vals)\n",
      "        output.write(row_line + \"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat data/mydata.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that there is actually a module in the standard library called `csv` which can also be used to read and write delimited files. There is some example code reading this same file using this library towards the end of this notebook. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a program that reads in a tab delimited file with 4 columns: gene, chromosome, start and end coordinates. Compute the length of each gene and print the name of each gene and its corresponding length, seperated by a space, to a new file. You can find an example file <a href=\"http://www.ebi.ac.uk/~grsr/perl/genes.txt\">here</a>, or in ` data/genes.txt` directory of the course materials.\n",
      "\n",
      "2. Write a program that extends the search_gzip_file.py script in the scripts directory to use a file containing sample accession numbers and writes out a csv file containing the accession number and a boolean value whether it is in the *1000genomes* data or not. **Hint**: preprocess the *1000genomes* data into a data structure that allows quick membership tests."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash \n",
      "cat scripts/search_gzip_file.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python scripts/search_gzip_file.py SRS006837"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fixed format files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a fixed format file, a fixed set of columns contain the same data:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "          1         2         3         4         5         6         7  \n",
      "01234567890123456789012345678901234567890123456789012345678901234567890123456789\n",
      "ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This makes it easy to \"grab\" the columns of interest, by simply slicing the corresponding columns from the line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = \"ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  \"\n",
      "print line[30:38]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A huge problem with fixed format files is that a value can \"overflow\" the field, and can either invalidate the record, or corrupt the whole file. Fixed format files tend to be old file formats that are still in use. An important one is the PDB-format to represent molecular structures. A simple parser would be:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readPDB(fileName):\n",
      "    \n",
      "    atoms = []\n",
      "    \n",
      "    for line in open( fileName ):\n",
      "        if line[:6] == \"ATOM  \":\n",
      "            x = float( line[30:38] )\n",
      "            y = float( line[38:46] )\n",
      "            z = float( line[46:54] )\n",
      "            atoms.append( (x, y, z) )\n",
      "    \n",
      "    return atoms\n",
      "\n",
      "atoms = readPDB(\"data/example.pdb\")\n",
      "print atoms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcCentroid(atoms):\n",
      "    \n",
      "    natoms = len( atoms )\n",
      "    \n",
      "    if natoms == 0:\n",
      "        return ( 0, 0, 0 )\n",
      "    \n",
      "    xsum = ysum = zsum = 0\n",
      "    \n",
      "    for ( x, y, z ) in atoms:\n",
      "        xsum += x\n",
      "        ysum += y\n",
      "        zsum += z\n",
      "        \n",
      "    return ( xsum / natoms, ysum / natoms, zsum / natoms )\n",
      "\n",
      "calcCentroid(atoms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "XML files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "XML files enclose data within data identifier fields (`<identifier>...</identifier>`). This is a very powerful, self-documenting format, but unfortunately, very hard to parse. There are several parsers included with the Python Standard Library. Here, we use the `xml.etree` module. This creates a tree-like structure of the data that can be accessed using natural Python syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printPubmedAbstract(xmlFile):\n",
      "    \n",
      "    from xml.etree import cElementTree as ElementTree\n",
      "    tree = ElementTree.parse(xmlFile)\n",
      "    root = tree.getroot()\n",
      "\n",
      "    citationElem = root.find('PubmedArticle/MedlineCitation')\n",
      "    pmid = citationElem.findtext('PMID')\n",
      "    articleElem = citationElem.find('Article')\n",
      "    journalElem = articleElem.find('Journal')\n",
      "    journalTitle = journalElem.findtext('Title')\n",
      "    journalYear = journalElem.findtext('JournalIssue/PubDate/Year')\n",
      "    articleTitle = articleElem.findtext('ArticleTitle')\n",
      "    articleAbstract = articleElem.findtext('Abstract/AbstractText')\n",
      "\n",
      "    print 'PMID = %s' % pmid\n",
      "    print 'journalYear = %s' % journalYear\n",
      "    print 'journalTitle = \"%s\"' % journalTitle\n",
      "    print 'articleTitle = \"%s\"' % articleTitle\n",
      "    print 'articleAbstract = \"%s\"' % articleAbstract\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printPubmedAbstract( \"data/pubmed.xml\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Python file library"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`os`:\n",
      "\n",
      "- `chdir(path)` : change the current working directory to be path\n",
      "- `getcwd()` : return the current working directory\n",
      "- `listdir(path)` : returns a list of files/directories in the directory path\n",
      "- `mkdir(path)` : create the directory path\n",
      "- `rmdir(path)` : remove the directory path\n",
      "- `remove(path)` : remove the file path\n",
      "- `rename(src, dst)` : move the file/directory from src to dst\n",
      "\n",
      "`os.path`:\n",
      "\n",
      "- `exists(path)` : returns whether path exists\n",
      "- `isfile(path)` : returns whether path is a \u201cregular\u201d file (as opposed to a directory)\n",
      "- `isdir(path)` : returns whether path is a directory\n",
      "- `islink(path)` : returns whether path is a symbolic link\n",
      "- `join(*paths)` : joins the paths together into one long path\n",
      "- `dirname(path)` : returns directory containing the path\n",
      "- `basename(path)` : returns the path minus the dirname(path) in front\n",
      "- `split(path)` : returns (dirname(path), basename(path))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "os.path.join( \"home\", \"test\", \"mydoc.txt\" )\n",
      "# home/test/mydoc.txt - Unix\n",
      "# home\\test\\mydoc.txt - Windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "System calls"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By using the `subprocess` module it is possible to run external programs from within Python. For example here we use the `call()` function to run the `makeblastdb` program (which creates a BLAST database from a sequence file). What we pass to this function is a list of textual arguments that correspond to what we would type an the command line if running the program from the operating system"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "\n",
      "cmdArgs = ['makeblastdb', '-dbtype', 'prot', '-in', 'mySeqFile.fasta', '-out', 'myDbName']\n",
      "  \n",
      "subprocess.call(cmdArgs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to capture any output using `check-output()`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "\n",
      "longDirList = subprocess.check_output( ['ls', '-l'] )\n",
      "\n",
      "print longDirList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More advanced control is achieved with `Popen()`. This creates an object that represets the process to be run and can control how data is sent and retrieved. For example here we use the `PIPE` value to connect Python to the standard input and output of the process and the `Popen.communicate()` function handles the data I/O allowing us to run the BLAST program (locally) without having to write/read any files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import Popen, PIPE\n",
      "\n",
      "fastaSeq = \"\"\">tr|B2R4C5|B2R4C5_HUMAN Lysozyme OS=Homo sapiens GN=LYZ PE=2 SV=1\n",
      "MKALIVLGLVLLSVTVQGKVFERCELARTLKRLGMDGYRGISLANWMCLAKWESGYNTRA\n",
      "TNYNAGDRSTDYGIFQINSRYWCNDGKTPGAVNACHLSCSALLQDNIADAVACAKRVVRD\n",
      "PQGIRAWVAWRNRCQNRDVRQYVQGCGV\"\"\"\n",
      "\n",
      "cmdArgs = ['blastp','-num_threads', '4', '-db', '/myDbLocation/uniref90',\n",
      "           '-evalue', '1e-4', '-matrix', 'BLOSUM62']\n",
      "  \n",
      "proc = Popen(cmdArgs, stdin=PIPE, stdout=PIPE)\n",
      "\n",
      "stdOutData, stdErrData = proc.communicate(fastaSeq)\n",
      "\n",
      "print stdOutData\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More advanced use would allow chaining a set of programs and calling one with the output of another. For more information, check the ``subprocess`` module documentation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a script that runs the UNIX command ls to get a list the files in the current directory, then prints out all upper case versions of all the file names.\n",
      "2. Modify your script to only print out Python files, i.e. those ending with '.py'"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using BioPython"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open( \"data/glpa.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reading FASTA files\n",
      "from Bio import SeqIO\n",
      "\n",
      "fileObj = open( \"data/glpa.fa\", \"rU\" )\n",
      "\n",
      "for protein in SeqIO.parse(fileObj, 'fasta'):\n",
      "  print protein.id\n",
      "  print protein.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Writing FASTA files\n",
      "from Bio.SeqRecord import SeqRecord\n",
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import IUPAC\n",
      "\n",
      "sequence = 'MYGKIIFVLLLSEIVSISASSTTGVAMHTSTSSSVTKSYISSQTNDTHKRDTYAATPRAHEVSEISVRTVYPPEEETGERVQLAHHFSEPEITLIIFG'\n",
      "\n",
      "fileObj = open( \"biopython.fa\", \"w\")\n",
      "  \n",
      "seqObj = Seq(sequence, IUPAC.protein)\n",
      "proteinObjs = [SeqRecord(seqObj, id=\"TEST\"),]\n",
      "\n",
      "SeqIO.write(proteinObjs, fileObj,  'fasta')\n",
      "\n",
      "fileObj.close()\n",
      "\n",
      "with open( \"biopython.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read FASTA file from NCBI GenBank\n",
      "from Bio import Entrez\n",
      "\n",
      "socketObj = Entrez.efetch(db=\"protein\", rettype=\"fasta\",\n",
      "                         id=\"71066805\")\n",
      "dnaObj = SeqIO.read(socketObj, \"fasta\")\n",
      "socketObj.close()\n",
      "\n",
      "print dnaObj.description\n",
      "print dnaObj.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read SWISSPROT record\n",
      "from Bio import ExPASy\n",
      "\n",
      "socketObj = ExPASy.get_sprot_raw('HBB_HUMAN')\n",
      "proteinObj = SeqIO.read(socketObj, \"swiss\")\n",
      "socketObj.close()\n",
      "\n",
      "print proteinObj.description\n",
      "print proteinObj.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More advanced examples"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Using the `csv` module to read delimited files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    fileObj.readline() # Remove header\n",
      "    reader = csv.reader( fileObj, delimiter = \" \" ) # delimiter defaults to \",\"\n",
      "    lines  = [l.strip().split(\" \") for l in fileObj]\n",
      "    #print list( reader )\n",
      "    print lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read from list\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    data = fileObj.readlines()\n",
      "\n",
      "import csv\n",
      "reader = csv.reader( data, delimiter = \" \" )\n",
      "print list( reader )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in as dictionary\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    reader = csv.DictReader( fileObj, delimiter = \" \" ) # do no remove header\n",
      "    print list( reader )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Write delimited files with the `csv module`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Using the csv module\n",
      "import csv\n",
      "\n",
      "mydata = [\n",
      "    ['1', 'Human', '1.076'], \n",
      "    ['2', 'Mouse', '1.202'], \n",
      "    ['3', 'Frog', '2.2362'], \n",
      "    ['4', 'Fly', '0.9853']\n",
      "]\n",
      "\n",
      "with open( \"csvdata.csv\", \"wb\" ) as fileObj:\n",
      "    writer = csv.writer( fileObj )\n",
      "    writer.writerow( [ \"Index\", \"Organism\", \"Score\" ] ) # write header\n",
      "\n",
      "    for record in mydata:\n",
      "        writer.writerow( record )\n",
      "\n",
      "# Note that data types are converted to string\n",
      "fileObj = open( \"csvdata.csv\", \"rb\" )\n",
      "reader = csv.reader( fileObj )\n",
      "print list( reader )\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recursive file search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def findFiles(directory, suffix):\n",
      "\n",
      "    files = []\n",
      "    dirfiles = os.listdir(directory)\n",
      "    \n",
      "    for dirfile in dirfiles:\n",
      "        fullfile = os.path.join(directory, dirfile)\n",
      "\n",
      "        if os.path.isdir(fullfile):\n",
      "            # fullfile is a directory, so recurse into that\n",
      "            files.extend(findFiles(fullfile, suffix))\n",
      "\n",
      "        elif dirfile.endswith(suffix):\n",
      "            # fullfile is a normal file, and with correct suffix\n",
      "            files.append(fullfile)\n",
      "\n",
      "    return files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recursive delete"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def removeFiles(directory, suffix):\n",
      "\n",
      "    dirfiles = os.listdir(directory)\n",
      "\n",
      "    for dirfile in dirfiles:\n",
      "        fullfile = os.path.join(directory, dirfile)\n",
      "\n",
      "        if os.path.isdir(fullfile):\n",
      "            # fullfile is a directory, so recurse into that\n",
      "            removeFiles(fullfile, suffix)\n",
      "\n",
      "        elif dirfile.endswith(suffix):\n",
      "            # fullfile is a normal file, and with correct suffix\n",
      "            os.remove(fullfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Writing FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def writeFastaSeqs(comments, sequences, fastaFile, width=60):\n",
      "\n",
      "    fileObj = open(fastaFile, \"w\")\n",
      "\n",
      "    for i, seq in enumerate(sequences):\n",
      "      \n",
      "        numLines = 1 + ( len(seq) - 1 ) / width\n",
      "        seqLines = [ seq[ width*x : width*(x+1) ] for x in range(numLines) ]\n",
      "      \n",
      "        seq = '\\n'.join(seqLines)\n",
      "        fileObj.write('> %s\\n%s\\n' % (comments[i], seq))\n",
      "\n",
      "    fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Reading FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readFastaFile(fileName):\n",
      "\n",
      "    fileObj = open(fileName, \"rU\")\n",
      "    sequences = []\n",
      "    seqFragments = []\n",
      "\n",
      "    for line in fileObj:\n",
      "        if line.startswith(\">\"):\n",
      "            # found start of next sequence\n",
      "            if seqFragments:\n",
      "                sequence = \"\".join(seqFragments)\n",
      "                sequences.append(sequence)\n",
      "        \n",
      "            seqFragments = []\n",
      "\n",
      "        else:\n",
      "            # found more of existing sequence\n",
      "            seq = line.rstrip() # remove carriage return\n",
      "            seqFragments.append(seq)\n",
      "\n",
      "    if seqFragments:\n",
      "        # should be the case if file is not empty\n",
      "        sequence = \"\".join(seqFragments)\n",
      "        sequences.append(sequence)\n",
      "\n",
      "    fileObj.close()\n",
      "\n",
      "    return sequences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sequences = readFastaFile( \"data/glpa.fa\" )\n",
      "print sequences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writeFastaSeqs( comments = [ \"GLPA_HUMAN\" ], sequences = sequences, fastaFile = \"myfasta.fa\" )\n",
      "\n",
      "with open( \"myfasta.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}