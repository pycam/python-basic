{
 "metadata": {
  "name": "Introduction_to_python_session_4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Frequently the data we want to operate on or analyse will be stored in files, so in our programs we need to be able to open files, read through them (perhaps all at once, perhaps not), and then close them. \n",
      "\n",
      "We will also frequently want to be able to print output to files rather than always printing out results to the terminal.\n",
      "\n",
      "Python supports all of these modes of operations on files, and provides a number of useful functions and syntax to make dealing with files straightforward."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "File objects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To open a file, python provies the `open` function, which takes a filename as its first argument and returns a _file object_ which is python's internal representation of the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"data/datafile.txt\"\n",
      "fileObj = open( path )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`open` takes an optional second argument specifying the _mode_ in which the file is opened, either for reading, writing or appending."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"r\" ) # open for reading, default\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"w\" ) # open for writing (existing files will be overwritten)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open( \"data/myfile.txt\", \"a\" ) # open for appending"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Mode modifiers__\n",
      "\n",
      "These mode strings can include some extra modifier characters that deal with issues in dealing with files across multiple platforms.\n",
      "\n",
      "`b`: binary mode, e.g. `\"rb\"`. No translation for end-of-line chanracters to platform specific setting value.\n",
      "\n",
      "`U`: universal new line mode, e.g. `\"rU\"`. Present end-of-line as `\"\\n\"` no matter where the file was written."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "File objects provide several methods for accessing data from and writing data to the file which we will see shortly, but you can also check the name of the file with `.name` attribute and the mode the file was opened in with `.mode`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fileObj.name\n",
      "print fileObj.mode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Error checking__\n",
      "\n",
      "If you try to open a file that doesn't exist, or that you don't have appropriate permissions to access python etc., will raise an `IOError` exception, which can catch with a `try` block as we saw yesterday."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    fileObj = open(\"doesnotexist.txt\", \"r\")\n",
      "    print fileObj.name\n",
      "except IOError:\n",
      "    print \"Oh no, we couldn't open our file!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Closing files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To close a file once you finished with it, you can call the `.close` method on a file object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading from files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we have opened a file for reading, file objects provide a number of methods for accessing the data in a file. The simplest of these is the `.read` method that reads the entire contents of the file into a string variable.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileObj = open( \"data/datafile.txt\" )\n",
      "print fileObj.read() # everything\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that if this means the entire file will be read into memory, if you are operating on a large file and don't actually need all the data at the same time this is rather inefficient.\n",
      "\n",
      "Frequently, we just need to operate on individuals lines of the file, and you can use the `.readline` method to read a line from a file and return it as a python string.\n",
      "\n",
      "File objects internally keep track of your current location in a file, so to get following lines from the file you can call this method multiple times.\n",
      "\n",
      "It is important to note that the string representing each line will have a trailing newline `\"\\n\"` character, which you may want to remove with the `.rstrip` string method.\n",
      "\n",
      "Once the end of the file is reached, `.readline` will return an empty string `''`. This is different from an apparently empty line in a file, as even an empty line will contain a newline character. Recall that the empty string is considered as `False` in python, so you can readily check for this condition with an `if` statement etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# one line at a time\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "print \"1st line: %r\" % fileObj.readline()\n",
      "print \"2nd line: %r\" % fileObj.readline()\n",
      "print \"3rd line: %r\" % fileObj.readline()\n",
      "print \"4th line: %r\" % fileObj.readline()\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To read in all lines from a file as a list of strings containing the data from each line, use the `.readlines` method (though note that this will again read all data into memory)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# all lines\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "\n",
      "lines = fileObj.readlines()\n",
      "\n",
      "print \"The file has\", len(lines), \"lines\"\n",
      "\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looping over the lines in a file is a very common operation and python lets you iterate over a file using a `for` loop just as if it were an array of strings. This does not read all data into memeory at once, and so is much more efficient that reading the file with `.readlines` and then looping over the resulting list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# as an iterable\n",
      "fileObj = open( \"data/datafile.txt\" )\n",
      "\n",
      "for line in fileObj:\n",
      "    print line.rstrip().upper()\n",
      "\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The with statement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is important that files are closed when they are no longer required, but writing ``fileObj.close()`` is tedious (and more importantly, easy to forget). An alternative syntax is to open the files within a ``with`` statement, in which case the file will automatically be closed at the end of the `with` block."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fileObj will be closed when leaving the block\n",
      "with open( \"data/datafile.txt\" ) as fileObj:\n",
      "    for ( i, line ) in enumerate( fileObj, start = 1 ):\n",
      "        print \"%s: %r\" % ( i, line )\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Writing to files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once a file has been opened for writing, you can use the `.write` method on a file object to write data to the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = open( \"out.txt\", \"w\" )\n",
      "output.write(\"GENE\\tREAD_COUNT\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The argument to the `.write` method must be a string, so if you want to write out numerical data to a file you will have to convert it to a string somehow beforehand.\n",
      "\n",
      "Remember to include a newline character to separate lines of your output, unlike the `print` statement, `.write` does not include this by default."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "read_counts = {\n",
      "    'BRCA2': 43234,\n",
      "    'FOXP2': 3245,\n",
      "    'SORT1': 343792\n",
      "}\n",
      "\n",
      "for gene in read_counts:\n",
      "    line = \"\\t\".join( [ gene, str(read_counts[gene]) ] )\n",
      "    output.write(line+\"\\n\")\n",
      "    \n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat out.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Be cautious when opening a file for writing, as python will happily let you overwrite any existing data in the file. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Exercises__\n",
      "\n",
      "1. Open a file for writing, and write your name into it.\n",
      "2. Write a script that takes the name of a file containing many lines of nucleotide sequence as a command line argument and opens the file for reading (checking that the filename supplied does exist). For each line in the file, print out the line number and the length of the corresponding line (There is an example file here: http://www.ebi.ac.uk/~grsr/perl/dna.txt).\n",
      "3. Write a Python version of the UNIX ``cat`` command that just prints it input onto its output. For convenience, make it accept a single argument, denoting a file where input should be read. The following command should work and produce identical output:\n",
      "\n",
      "* ``cat.py < my.name`` # read from standard input\n",
      "* ``cat.py my.name`` # read from a file\n",
      "\n",
      "**Hint**: standard input and standard output filehandles are available as ``sys.stdin`` and ``sys.stdout`` after importing the ``sys`` module.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data formats"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bioinformaticians love creating endless new file formats for their data, but there are a number of very common standard formats that it is good to get used to parsing.\n",
      "\n",
      "Fixed width (or columns):"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  \n",
      "ATOM    474  CA  SER A  92      10.391   7.707   5.748  1.00  0.87           C  \n",
      "ATOM    475  C   SER A  92      11.422   7.439   6.842  1.00  0.94           C  \n",
      "ATOM    476  O   SER A  92      12.423   8.118   6.941  1.00  1.07           O "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Delimited:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "X 169008682 1 111267453 1.0976\n",
      "2 8265484 5 69763543 4.9825\n",
      "MT 10924 MT 81934 7.2357\n",
      "3 127 8 10908776 1.2509"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Structured (or mark-up):"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "<PDBx:atom_site id=\"16809\">\n",
      "         <PDBx:Cartn_x>-5.882</PDBx:Cartn_x>\n",
      "         <PDBx:Cartn_y>-7.295</PDBx:Cartn_y>\n",
      "         <PDBx:Cartn_z>0.189</PDBx:Cartn_z>\n",
      "         <PDBx:label_asym_id>B</PDBx:label_asym_id>\n",
      "         <PDBx:label_atom_id>N</PDBx:label_atom_id>\n",
      "         <PDBx:label_comp_id>GLY</PDBx:label_comp_id>\n",
      "         <PDBx:label_entity_id>1</PDBx:label_entity_id>\n",
      "      </PDBx:atom_site>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Delimited files"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Read delimited files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readListFile(fileName, converters, delimiter = \" \"):\n",
      "    dataList = []\n",
      "    fileObj = open(fileName, 'rU')\n",
      "    header = fileObj.readline() # Extract first line\n",
      "\n",
      "    # Loop through remaining lines\n",
      "    for line in fileObj:\n",
      "        data = line.rstrip().split( delimiter )\n",
      "\n",
      "        for ( index, datum ) in enumerate( data ):\n",
      "          convertFunc = converters[index]\n",
      "     \n",
      "          if convertFunc:\n",
      "            data[index] = convertFunc( data[ index ] )\n",
      "\n",
      "        dataList.append(data)\n",
      "   \n",
      "    fileObj.close()\n",
      "    return dataList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print readListFile( \"data/mydata.txt\", converters = ( None, None, None ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydata = readListFile( \"data/mydata.txt\", converters = ( int, str, float ) )\n",
      "print mydata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is such a common task that it is available in the standard Python library ``csv`` module. It is very flexible, but does not support automatic conversions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    fileObj.readline() # Remove header\n",
      "    reader = csv.reader( fileObj, delimiter = \" \" ) # delimiter defaults to \",\"\n",
      "    print list( reader )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read from list\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    data = fileObj.readlines()\n",
      "\n",
      "import csv\n",
      "reader = csv.reader( data, delimiter = \" \" )\n",
      "print list( reader )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in as dictionary\n",
      "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
      "    reader = csv.DictReader( fileObj, delimiter = \" \" ) # do no remove header\n",
      "    print list( reader )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Write delimited files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def writeListFile(fileName, data, headings, formats, separator=' '):\n",
      "\n",
      "    if len(data[0]) != len(headings):\n",
      "        print \"Headings length does not match input list\"\n",
      "        return\n",
      "    \n",
      "    if len(formats) != len(headings):\n",
      "        print \"Formats length does not match input list\"\n",
      "        return\n",
      "\n",
      "    fileObj = open(fileName, 'w') # Should really check more\n",
      "  \n",
      "    line = separator.join(headings)\n",
      "    fileObj.write('%s\\n' % line)\n",
      "\n",
      "    for record in data:\n",
      "        line = separator.join( [ f % r  for ( f, r ) in zip( formats, record ) ] )\n",
      "        fileObj.write('%s\\n' % line)\n",
      "\n",
      "    fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writeListFile(\n",
      "    fileName = \"mywriter.txt\",\n",
      "    data = mydata,\n",
      "    headings = ( \"Index\", \"Organism\", \"Score\" ), \n",
      "    formats = ( \"%d\", \"%s\", \"%.2f\" ),\n",
      "    )\n",
      "\n",
      "with open( \"mywriter.txt\" ) as fileObj:\n",
      "    print fileObj.read()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Using the csv module\n",
      "import csv\n",
      "\n",
      "with open( \"csvdata.csv\", \"wb\" ) as fileObj:\n",
      "    writer = csv.writer( fileObj )\n",
      "    writer.writerow( [ \"Index\", \"Organism\", \"Score\" ] ) # write header\n",
      "\n",
      "    for record in mydata:\n",
      "        writer.writerow( record )\n",
      "\n",
      "# Note that data types are converted to string\n",
      "fileObj = open( \"csvdata.csv\", \"rb\" )\n",
      "reader = csv.reader( fileObj )\n",
      "print list( reader )\n",
      "fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash \n",
      "cat scripts/search_gzip_file.py\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python scripts/search_gzip_file.py SRS006837"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a program that extends the search_gzip_file.py script to use a file containing sample accession numbers and writes out a csv-file containing the accession number and a boolean value whether it is in the *1000genomes* data or not. **Hint**: preprocess the *1000genomes* data into a data structure that allows quick membership tests."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fixed format files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a fixed format file, a fixed set of columns contain the same data:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "          1         2         3         4         5         6         7  \n",
      "01234567890123456789012345678901234567890123456789012345678901234567890123456789\n",
      "ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This makes it easy to \"grab\" the columns of interest, by simply slicing the corresponding columns from the line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = \"ATOM    473  N   SER A  92      10.056   6.423   5.078  1.00  0.73           N  \"\n",
      "print line[30:38]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A huge problem with fixed format files is that a value can \"overflow\" the field, and can either invalidate the record, or corrupt the whole file. Fixed format files tend to be old file formats that are still in use. An important one is the PDB-format to represent molecular structures. A simple parser would be:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readPDB(fileName):\n",
      "    \n",
      "    atoms = []\n",
      "    \n",
      "    for line in open( fileName ):\n",
      "        if line[:6] == \"ATOM  \":\n",
      "            atoms.append(\n",
      "                ( float( line[30:38] ), float( line[38:46] ), float( line[46:54] ) )\n",
      "                )\n",
      "    \n",
      "    return atoms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcCentroid(atoms):\n",
      "    \n",
      "    natoms = len( atoms )\n",
      "    \n",
      "    if natoms == 0:\n",
      "        return ( 0, 0, 0 )\n",
      "    \n",
      "    xsum = ysum = zsum = 0\n",
      "    \n",
      "    for ( x, y, z ) in atoms:\n",
      "        xsum += x\n",
      "        ysum += y\n",
      "        zsum += z\n",
      "        \n",
      "    return ( xsum / natoms, ysum / natoms, zsum / natoms )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "XML files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "XML files enclose data within data identifier fields (`<identifier>...</identifier>`). This is a very powerful, self-documenting format, but unfortunately, very hard to parse. There are several parsers included with the Python Standard Library. Here, we use the `xml.etree` module. This creates a tree-like structure of the data that can be accessed using natural Python syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printPubmedAbstract(xmlFile):\n",
      "    \n",
      "    from xml.etree import cElementTree as ElementTree\n",
      "    tree = ElementTree.parse(xmlFile)\n",
      "    root = tree.getroot()\n",
      "\n",
      "    citationElem = root.find('PubmedArticle/MedlineCitation')\n",
      "    pmid = citationElem.findtext('PMID')\n",
      "    articleElem = citationElem.find('Article')\n",
      "    journalElem = articleElem.find('Journal')\n",
      "    journalTitle = journalElem.findtext('Title')\n",
      "    journalYear = journalElem.findtext('JournalIssue/PubDate/Year')\n",
      "    articleTitle = articleElem.findtext('ArticleTitle')\n",
      "    articleAbstract = articleElem.findtext('Abstract/AbstractText')\n",
      "\n",
      "    print 'PMID = %s' % pmid\n",
      "    print 'journalYear = %s' % journalYear\n",
      "    print 'journalTitle = \"%s\"' % journalTitle\n",
      "    print 'articleTitle = \"%s\"' % articleTitle\n",
      "    print 'articleAbstract = \"%s\"' % articleAbstract\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printPubmedAbstract( \"data/pubmed.xml\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Python file library"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`os`:\n",
      "\n",
      "- `chdir(path)` : change the current working directory to be path\n",
      "- `getcwd()` : return the current working directory\n",
      "- `listdir(path)` : returns a list of files/directories in the directory path\n",
      "- `mkdir(path)` : create the directory path\n",
      "- `rmdir(path)` : remove the directory path\n",
      "- `remove(path)` : remove the file path\n",
      "- `rename(src, dst)` : move the file/directory from src to dst\n",
      "\n",
      "`os.path`:\n",
      "\n",
      "- `exists(path)` : returns whether path exists\n",
      "- `isfile(path)` : returns whether path is a \u201cregular\u201d file (as opposed to a directory)\n",
      "- `isdir(path)` : returns whether path is a directory\n",
      "- `islink(path)` : returns whether path is a symbolic link\n",
      "- `join(*paths)` : joins the paths together into one long path\n",
      "- `dirname(path)` : returns directory containing the path\n",
      "- `basename(path)` : returns the path minus the dirname(path) in front\n",
      "- `split(path)` : returns (dirname(path), basename(path))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "os.path.join( \"home\", \"test\", \"mydoc.txt\" )\n",
      "# home/test/mydoc.txt - Unix\n",
      "# home\\test\\mydoc.txt - Windows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "System calls"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to run external programs from Python, and capture the output. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "\n",
      "out = subprocess.check_output( [ \"pwd\" ] )\n",
      "print out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This allows getting output from a program and processing it with Python. More advanced uses would allow chaining a set of programs and calling one with the output of another. For more information, check the ``subprocess`` module."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a script that runs the UNIX command ls to get a list the files in the current directory, then prints out all upper case versions of all the file names.\n",
      "2. Modify your script to only print out Python files, i.e. those ending with '.py'"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Examples"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recursive file search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def findFiles(directory, suffix):\n",
      "\n",
      "    files = []\n",
      "    dirfiles = os.listdir(directory)\n",
      "    \n",
      "    for dirfile in dirfiles:\n",
      "        fullfile = os.path.join(directory, dirfile)\n",
      "\n",
      "        if os.path.isdir(fullfile):\n",
      "            # fullfile is a directory, so recurse into that\n",
      "            files.extend(findFiles(fullfile, suffix))\n",
      "\n",
      "        elif dirfile.endswith(suffix):\n",
      "            # fullfile is a normal file, and with correct suffix\n",
      "            files.append(fullfile)\n",
      "\n",
      "    return files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recursive delete"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def removeFiles(directory, suffix):\n",
      "\n",
      "    dirfiles = os.listdir(directory)\n",
      "\n",
      "    for dirfile in dirfiles:\n",
      "        fullfile = os.path.join(directory, dirfile)\n",
      "\n",
      "        if os.path.isdir(fullfile):\n",
      "            # fullfile is a directory, so recurse into that\n",
      "            removeFiles(fullfile, suffix)\n",
      "\n",
      "        elif dirfile.endswith(suffix):\n",
      "            # fullfile is a normal file, and with correct suffix\n",
      "            os.remove(fullfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "High-level file operation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Python Standard library provides a lot of useful functions for file manipulation. E.g. recursively deleting a directory is simply ``shutil.rmtree( dirname )``. Here is the help-page for the command."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shutil\n",
      "print shutil.rmtree.__doc__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further useful functions from this module are ``copy`` and ``copytree``."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: to delete a file, use ``os.remove``. To remove a directory that is empty, use ``os.rmdir``."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Examples"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open( \"data/glpa.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Writing FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def writeFastaSeqs(comments, sequences, fastaFile, width=60):\n",
      "\n",
      "    fileObj = open(fastaFile, \"w\")\n",
      "\n",
      "    for i, seq in enumerate(sequences):\n",
      "      \n",
      "        numLines = 1 + ( len(seq) - 1 ) / width\n",
      "        seqLines = [ seq[ width*x : width*(x+1) ] for x in range(numLines) ]\n",
      "      \n",
      "        seq = '\\n'.join(seqLines)\n",
      "        fileObj.write('> %s\\n%s\\n' % (comments[i], seq))\n",
      "\n",
      "    fileObj.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Reading FASTA files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readFastaFile(fileName):\n",
      "\n",
      "    fileObj = open(fileName, \"rU\")\n",
      "    sequences = []\n",
      "    seqFragments = []\n",
      "\n",
      "    for line in fileObj:\n",
      "        if line.startswith(\">\"):\n",
      "            # found start of next sequence\n",
      "            if seqFragments:\n",
      "                sequence = \"\".join(seqFragments)\n",
      "                sequences.append(sequence)\n",
      "        \n",
      "            seqFragments = []\n",
      "\n",
      "        else:\n",
      "            # found more of existing sequence\n",
      "            seq = line.rstrip() # remove carriage return\n",
      "            seqFragments.append(seq)\n",
      "\n",
      "    if seqFragments:\n",
      "        # should be the case if file is not empty\n",
      "        sequence = \"\".join(seqFragments)\n",
      "        sequences.append(sequence)\n",
      "\n",
      "    fileObj.close()\n",
      "\n",
      "    return sequences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sequences = readFastaFile( \"data/glpa.fa\" )\n",
      "print sequences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writeFastaSeqs( comments = [ \"GLPA_HUMAN\" ], sequences = sequences, fastaFile = \"myfasta.fa\" )\n",
      "\n",
      "with open( \"myfasta.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using BioPython"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reading FASTA files\n",
      "from Bio import SeqIO\n",
      "\n",
      "fileObj = open( \"data/glpa.fa\", \"rU\" )\n",
      "\n",
      "for protein in SeqIO.parse(fileObj, 'fasta'):\n",
      "  print protein.id\n",
      "  print protein.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Writing FASTA files\n",
      "from Bio.SeqRecord import SeqRecord\n",
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import IUPAC\n",
      "\n",
      "fileObj = open( \"biopython.fa\", \"w\")\n",
      "  \n",
      "seqObj = Seq(sequences[0], IUPAC.protein)\n",
      "proteinObjs = [SeqRecord(seqObj, id=\"TEST\"),]\n",
      "\n",
      "SeqIO.write(proteinObjs, fileObj,  'fasta')\n",
      "\n",
      "fileObj.close()\n",
      "\n",
      "with open( \"biopython.fa\" ) as fileObj:\n",
      "    print fileObj.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read FASTA file from NCBI GenBank\n",
      "from Bio import Entrez\n",
      "\n",
      "socketObj = Entrez.efetch(db=\"protein\", rettype=\"fasta\",\n",
      "                         id=\"71066805\")\n",
      "dnaObj = SeqIO.read(socketObj, \"fasta\")\n",
      "socketObj.close()\n",
      "\n",
      "print dnaObj.description\n",
      "print dnaObj.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read SWISSPROT record\n",
      "from Bio import ExPASy\n",
      "\n",
      "socketObj = ExPASy.get_sprot_raw('HBB_HUMAN')\n",
      "proteinObj = SeqIO.read(socketObj, \"swiss\")\n",
      "socketObj.close()\n",
      "\n",
      "print proteinObj.description\n",
      "print proteinObj.seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}